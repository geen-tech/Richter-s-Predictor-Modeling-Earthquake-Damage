{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b974a01",
   "metadata": {},
   "source": [
    "# Main Pipeline Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ab732",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from preprocessing import load_and_preprocess\n",
    "from models import train_ensemble\n",
    "from metrics_utils import compute_metrics, plot_confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73137cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento + preprocessing\n",
    "X_enc, y, X_test_enc, test_index = load_and_preprocess(Path(\"data\"))\n",
    "\n",
    "# Addestramento + valutazione\n",
    "all_true = []\n",
    "all_pred = []\n",
    "for y_val, pred in train_ensemble(X_enc, y):\n",
    "    all_true.extend(y_val)\n",
    "    all_pred.extend(pred)\n",
    "\n",
    "# Valutazione complessiva\n",
    "metrics = compute_metrics(all_true, all_pred)\n",
    "print(metrics)\n",
    "\n",
    "# Confusion Matrix\n",
    "plot_confusion_matrix(all_true, all_pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
